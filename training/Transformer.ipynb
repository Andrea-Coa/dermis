{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuTCnUEEjZuh"
      },
      "outputs": [],
      "source": [
        "#vectorize them into numerical vector\n",
        "#positional embedings because of the presence of an ingredient in a product\n",
        "#bert\n",
        "#six transformers encoder layers\n",
        "#which consist of two multi-head attention blocks and feed-forward blocks with normalization\n",
        "#We used weighted binary cross-entropy loss to diminish the effects of class imbalances by utilizing the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import defaultdict\n",
        "\n",
        "class SkincareTransformer(nn.Module):\n",
        "    def __init__(self, num_classes, d_model=256, nhead=8, num_layers=6):\n",
        "        super(SkincareTransformer, self).__init__()\n",
        "        self.ingredient_embedding = nn.Embedding(num_embeddings=10000, embedding_dim=d_model)\n",
        "        #print(\"ingredient_embeding: \", self.ingredient_embedding)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ingredient_embedding(x)\n",
        "        x = self.layer_norm(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[0, :, :]\n",
        "        logits = self.classifier(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "cgpsmxqao9oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ingredients(products):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    all_ingredients = set()\n",
        "\n",
        "    for product in products:\n",
        "        for ing in product['ingredients']:\n",
        "            ing_clean = ing.lower().strip()\n",
        "            tokens = tokenizer.tokenize(ing_clean)\n",
        "            all_ingredients.update(tokens)\n",
        "    ingredient_to_idx = {ing: idx+1 for idx, ing in enumerate(all_ingredients)}\n",
        "    return ingredient_to_idx"
      ],
      "metadata": {
        "id": "tW_fzM0jp33g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_products(products, ingredient_to_idx, max_len=100):\n",
        "    vectors = []\n",
        "    for product in products:\n",
        "        ing_indices = []\n",
        "        for ing in product['ingredients']:\n",
        "            tokens = tokenizer.tokenize(ing.lower().strip())\n",
        "            ing_indices.extend([ingredient_to_idx.get(t, 0) for t in tokens])\n",
        "            print(\"ingrediente: \", ing, \" :  \", tokens)\n",
        "        if len(ing_indices) > max_len:\n",
        "            ing_indices = ing_indices[:max_len]\n",
        "        else:\n",
        "            ing_indices += [0] * (max_len - len(ing_indices))\n",
        "\n",
        "        vectors.append(ing_indices)\n",
        "    return torch.tensor(vectors)"
      ],
      "metadata": {
        "id": "FjECqeNGp6cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkincareRecommender:\n",
        "    def __init__(self, dermatologist_routine):\n",
        "        self.routine = dermatologist_routine\n",
        "        self.models = {}\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.ingredient_to_idx = {}\n",
        "        self.max_len = 100\n",
        "        self._initialize_ingredient_mapping(dermatologist_routine['approved_products'])\n",
        "\n",
        "    def _initialize_ingredient_mapping(self, approved_products):\n",
        "        all_ingredients = set()\n",
        "\n",
        "        for category, products in approved_products.items():\n",
        "            for product in products:\n",
        "                for ing in product['ingredients']:\n",
        "                    ing_clean = ing.lower().strip()\n",
        "                    tokens = self.tokenizer.tokenize(ing_clean)\n",
        "                    all_ingredients.update(tokens)\n",
        "\n",
        "        self.ingredient_to_idx = {ing: idx+1 for idx, ing in enumerate(all_ingredients)}\n",
        "\n",
        "    def _prepare_data(self, products):\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        for product in products:\n",
        "            ing_indices = []\n",
        "            for ing in product['ingredients']:\n",
        "                tokens = self.tokenizer.tokenize(ing.lower().strip())\n",
        "                ing_indices.extend([self.ingredient_to_idx.get(t, 0) for t in tokens])\n",
        "\n",
        "            if len(ing_indices) > self.max_len:\n",
        "                ing_indices = ing_indices[:self.max_len]\n",
        "            else:\n",
        "                ing_indices += [0] * (self.max_len - len(ing_indices))\n",
        "\n",
        "            X.append(ing_indices)\n",
        "            y.append(1.0)\n",
        "\n",
        "        return torch.tensor(X, dtype=torch.long), torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def _vectorize_product(self, product):\n",
        "        ing_indices = []\n",
        "        for ing in product['ingredients']:\n",
        "            tokens = self.tokenizer.tokenize(ing.lower().strip())\n",
        "            ing_indices.extend([self.ingredient_to_idx.get(t, 0) for t in tokens])\n",
        "\n",
        "        if len(ing_indices) > self.max_len:\n",
        "            ing_indices = ing_indices[:self.max_len]\n",
        "        else:\n",
        "            ing_indices += [0] * (self.max_len - len(ing_indices))\n",
        "\n",
        "        return torch.tensor([ing_indices], dtype=torch.long)\n",
        "\n",
        "    def train(self, approved_products):\n",
        "        for category, products in approved_products.items():\n",
        "            X, y = self._prepare_data(products)\n",
        "            model = SkincareTransformer(num_classes=1, d_model=128)\n",
        "            criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]))\n",
        "            optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "            for epoch in range(5):\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                print(f\"Category {category}, Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "            self.models[category] = model\n",
        "\n",
        "    def recommend(self, input_products):\n",
        "        recommendations = defaultdict(list)\n",
        "\n",
        "        for product in input_products:\n",
        "            X = self._vectorize_product(product)\n",
        "\n",
        "            for category, model in self.models.items():\n",
        "                if category in self.routine['steps']:\n",
        "                    with torch.no_grad():\n",
        "                        score = torch.sigmoid(model(X)).item()\n",
        "                    recommendations[category].append((product, score))\n",
        "        final_recommendations = {}\n",
        "        for category, candidates in recommendations.items():\n",
        "            if candidates:\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                final_recommendations[category] = candidates[0][0]\n",
        "\n",
        "        return final_recommendations"
      ],
      "metadata": {
        "id": "FEg-5TCDp4sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prueba\n",
        "dermatologist_routine = {\n",
        "    'skin_type': 'dry',\n",
        "    'steps': ['cleanser', 'moisturizer'],\n",
        "    'approved_products': {\n",
        "        'cleanser': [\n",
        "            {'name': 'CeraVe', 'ingredients': ['ceramides', 'hyaluronic acid']},\n",
        "            {'name': 'Cetaphil', 'ingredients': ['glycerin', 'niacinamide']}\n",
        "        ],\n",
        "        'moisturizer': [\n",
        "            {'name': 'Vanicream', 'ingredients': ['glycerin', 'squalane']},\n",
        "            {'name': 'Eucerin', 'ingredients': ['urea', 'ceramides']}\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# prods sinteticos\n",
        "input_products = [\n",
        "    {'name': 'Product A', 'ingredients': ['ceramides', 'hyaluronic acid', 'niacinamide']},\n",
        "    {'name': 'Product B', 'ingredients': ['glycerin', 'shea butter', 'squalane']},\n",
        "    {'name': 'Product C', 'ingredients': ['urea', 'ceramides', 'lactic acid']}\n",
        "]\n",
        "\n",
        "\n",
        "recommender = SkincareRecommender(dermatologist_routine)\n",
        "recommender.train(dermatologist_routine['approved_products'])\n",
        "recommendations = recommender.recommend(input_products)\n",
        "\n",
        "print(\"\\nProductos recomendados:\")\n",
        "for category, product in recommendations.items():\n",
        "    print(f\"{category}: {product['name']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qByKxkdro74t",
        "outputId": "094af0ae-656a-429c-ba36-62682b4aa8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ingredient_embeding:  Embedding(10000, 128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category cleanser, Epoch 0, Loss: 1.261245608329773\n",
            "Category cleanser, Epoch 1, Loss: 0.3210048973560333\n",
            "Category cleanser, Epoch 2, Loss: 0.12506555020809174\n",
            "Category cleanser, Epoch 3, Loss: 0.06397704780101776\n",
            "Category cleanser, Epoch 4, Loss: 0.04701791703701019\n",
            "ingredient_embeding:  Embedding(10000, 128)\n",
            "Category moisturizer, Epoch 0, Loss: 1.0994694232940674\n",
            "Category moisturizer, Epoch 1, Loss: 0.33272960782051086\n",
            "Category moisturizer, Epoch 2, Loss: 0.1203751266002655\n",
            "Category moisturizer, Epoch 3, Loss: 0.05480682849884033\n",
            "Category moisturizer, Epoch 4, Loss: 0.03442738205194473\n",
            "\n",
            "Productos recomendados:\n",
            "cleanser: Product A\n",
            "moisturizer: Product C\n"
          ]
        }
      ]
    }
  ]
}