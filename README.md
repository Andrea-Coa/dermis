
![](/dermis/assets/logo_dermis_frase.png)  
---
Dermis es un producto de datos en formato de aplicaci√≥n que mediante algoritmos de machine learning reconoce tu tipo de piel y condiciones para recomendarte una rutina de cuidado de la piel personalizada. Cada producto con ingredientes que ayuden a tus necesidades espec√≠ficas.

# Data Wrangling
Nuestro proyecto maneja varios tipos de datos: im√°genes, csv's, pdf's. En esta secci√≥n especificaremos c√≥mo preprocesamos cada uno y cu√°l es su funci√≥n en el proyecto.
* **Im√°genes**: Utilizamos un vol√∫men de im√°genes de rostros para entrenar los dos modelos de predicci√≥n que manejamos: *Logistic Regression* (para la predicci√≥n de condiciones en la piel), *Convolutional Neural Network (240 imgs)* (para la predicci√≥n de tipo de piel ). En ambos aplicamos *data augmentation* para no sesgar a clases minoritarias, obtener data m√°s granular como im√°genes con distinta iluminaci√≥n y orientaci√≥n (horizontal).Luego, como se puede observar en el extracto de pipeline, Fig. 1, uniformizamos el tama√±o de las im√°genes para el correcto manejo de par√°metros y buenas pr√°cticas.

![Fig. 1](/dermis/assets/pipeline_im.png)

Cabe resaltar, que para la inferencia de los modelos, las im√°genes ingresadas por los usuarios, tambi√©n pasar√°n por el pipeline de corte de tama√±o.
* **Archivos pdf's**: Utilizamos archivos pdf's ya que las fichas t√©cnicas de los qu√≠micos presentes en ingredientes de productos de cuidado de la piel, fueron obtenidos en ese formato. En este caso, el preprocesamiento m√°s que todo fue poder extraer la data dentro del pdf, es decir, de cada ingrediente qu√≠mico poder obtener las condiciones a las que combatia o actuaba y almacenarlos en un csv.
![Fig. 2](/dermis/assets/pipeline_ft.png)

* **csv' s**: La data de productos scrapeados de las farmacias y distribuidoras de productos, fueron alamacenados en csv's y analizados exhaustivamente para uniformizar la escritura de los ingredientes, categor√≠zas de los productos, como : *"moisturizer"*, *"serums"*...
La data utilizada para el EDA se puede encontrar en este [Google Drive](https://drive.google.com/drive/folders/108uniNHXUsphg3Wv_l5kBHt06mjvnzr0?usp=sharing).

---
### Data Modeling
![Fig. 3](/dermis/assets/arqui.png)

* **Transformer | Self attention entre los ingredientes de productos de nuestro *dataset* y los del libro**
Para explicar

# üß† **Arquitectura del flujo de Dermis**

Nuestro sistema combina aprendizaje autom√°tico, an√°lisis de grafos, scraping de productos, y reglas basadas en literatura dermatol√≥gica para generar rutinas de skincare personalizadas.

### 1. **Input del Usuario**

* Foto frontal del rostro (imagen 1)
* Foto lateral del rostro (imagen 2)
* Informaci√≥n adicional: ¬øTiene piel sensible?

### 2. **An√°lisis de im√°genes**

* **Foto Frontal ‚Üí Modelo de Regresi√≥n Log√≠stica**
  ![Fig. 4](/dermis/assets/reg_log.png)
Este proyecto usa EfficientNet-B0 preentrenado como extractor de caracter√≠sticas para im√°genes, eliminando su capa final. Las im√°genes se transforman (224x224, ToTensor) y se procesan con un DataLoader. Las representaciones obtenidas se usan como entrada para un modelo de clasificaci√≥n multietiqueta basado en LogisticRegression, envuelto con MultiOutputClassifier para manejar m√∫ltiples etiquetas por muestra. Se entrena usando class_weight='balanced' para mitigar el desbalance de clases.
```python
logistic = MultiOutputClassifier(LogisticRegression(max_iter=1000, class_weight='balanced'))
logistic.fit(X, y)
```

* **Foto Lateral ‚Üí Red Neuronal Convolucional (CNN)**
 ![Fig. 5](/dermis/assets/cnn_pipe.png) 
```python
# Aqu√≠ va el bloque de c√≥digo de CNN
```

Ambos modelos permiten identificar condiciones cut√°neas (como acn√©, rojeces, manchas, etc.)

### 3. **Sistema de Recomendaci√≥n Basado en Grafo**

* Las condiciones detectadas son nodos que se conectan a ingredientes beneficiosos.
* Los ingredientes se conectan a productos obtenidos v√≠a scraping.

Esta red permite filtrar productos alineados con las necesidades de la piel del usuario.

### 4. **Clasificaci√≥n de Tipo de Piel (basado en dermatolog√≠a cl√≠nica)**

* Utilizamos la informaci√≥n del usuario (sensibilidad + condiciones detectadas) para inferir su tipo de piel seg√∫n un libro de referencia dermatol√≥gica que define **16 tipos de piel**.
* De este tipo de piel se extrae un conjunto de productos ideales (seg√∫n el libro) con sus ingredientes.

### 5. **Refinamiento con Transformer de Atenci√≥n**

* Comparaci√≥n entre productos del grafo y productos del libro con transformer de atenci√≥n para obtener el set final personalizado.

```python
    def recommend(self, input_products):
        recommendations = defaultdict(list)

        for product in input_products:
            X = self._vectorize_product(product)

            for category, model in self.models.items():
                if category in self.routine['steps']:
                    with torch.no_grad():
                        score = torch.sigmoid(model(X)).item()
                    recommendations[category].append((product, score))
        final_recommendations = {}
        for category, candidates in recommendations.items():
            if candidates:
                candidates.sort(key=lambda x: x[1], reverse=True)
                final_recommendations[category] = candidates[0][0]

        return final_recommendations
```

* Los productos finales se clasifican seg√∫n su funci√≥n: **Limpiar**, **Tratar**, **Proteger**.

---

# ‚öôÔ∏è **Backend**

El backend de Dermis tiene varios componentes. Los servidores que sirven los modelos est√°n en una aplicaci√≥n de Flask, y lo restante (usuarios, productos) est√° en Lambda y API Gateway de AWS. 
 ![Fig. 5](/dermis/assets/back.png) 

## **Modelos de Machine Learning**

Se recomienda usar versi√≥n 3.11 de Python.

### **Detecci√≥n de tipo y condiciones de la piel**:

```{bash}
cd .\backend\redes\
```

Crear un entorno virtual de Python e instalar dependencias:

```{bash}
python -m venv .venv
.\.venv\Scripts\activate

pip install -r requirements_with_versions.txt
```
```{bash}
python .\app.py
```

El puerto por default es 5000, pero se puede cambiar en el archivo `app.py`.


### **Creaci√≥n de rutinas:**

```{bash}
cd .\backend\transformer\
```

Crear un entorno virtual de Python e instalar dependencias:

```{bash}
python -m venv .venv
.\.venv\Scripts\activate

pip install -r requirements.txt
```

```{bash}
python .\app.py
```

El puerto por default es 5001, pero se puede cambiar en el archivo `app.py`.


### Deployment en AWS

Para las bases de datos y otros componentes del backend, utilizamos servicios de AWS. Es necesario que la cuenta tenga los permisos adecuados para crear y gestionar los siguientes recursos:

- CloudFormation,
- Secrets Manager,
- EC2,
- S3,
- Lambda, 
- API Gateway.

A continuaci√≥n se detallan los pasos para desplegar el backend en AWS:

1. Configuraci√≥n de credenciales de AWS: Aseg√∫rate de tener instalado AWS CLI y configurado con tus credenciales de AWS en el archivo ```~\.aws```. Puedes editarlo manualmente o utilizar el comando:

   ```bash
   aws configure
   ```

* ****

# üì± **Frontend / Interfaz de Usuario**

En la app, el usuario puede:

* Ver la rutina recomendada dividida por funci√≥n (Limpiar, Tratar, Proteger).
* Consultar:

  * Precio
  * Descripci√≥n
  * Ranking de cada producto
* Generar con un clic las **instrucciones de uso paso a paso**.
* Brindar **feedback sobre la rutina** recibida.

Para utilizar el frontend se requiere ```npm```. Adem√°s, instalar **Expo Go** en el dispositivo m√≥vil para visualizar la app:

```{bash}
cd .\dermis\
```

Instalar dependencias:

```{bash}
npm install
```

Correr la aplicaci√≥n:

```{bash}
npx expo start
```

---

# üîß **Tecnolog√≠as Utilizadas**

* **Scraping** Python: BeautifulSoup, Selenium
* **Backend:** Python (Flask), scraping con BeautifulSoup
* **Modelos:** Scikit-learn (Regresi√≥n Log√≠stica), PyTorch (CNN y Transformer)
* **Frontend:** React Native con Expo
* **Base de Datos:** PostgreSQL + S3



## **Buit By** Camila Acosta | Andrea Coa | Jimena Gurbill√≥n
